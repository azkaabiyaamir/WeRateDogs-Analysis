{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report explains the data wrangling and analysis of the twitter activity of a Twitter account with the handle @WeRateDogs. WeRateDogs rate people’s dogs for fun.\n",
    "There were three sources of data:\n",
    "\n",
    "1)\tA .csv file which could be downloaded directly. This file had raw data about the tweets in the Twitter WeRateDogs archive.\n",
    "\n",
    "\n",
    "2)\tA .tsv file containing image predictions for the tweets of the @WeRateDogs twitter account.\n",
    "\n",
    "\n",
    "3)\tAdditional data from the Twitter API, tweepy which could be accessed in the form of a json data.\n",
    "\n",
    "\n",
    "The data from these three sources were separately translated into three individual tables. The data in these tables was messy and untidy. I assessed the data through the means of code as well as visual assessment. I was able to identify 8 Quality issues and 3 Tidiness issues as stated below:\n",
    "\n",
    "### Quality Issues:\n",
    "\n",
    "***t_archive***\n",
    "\n",
    "1.Wrong data type for 'timestamp' column. \n",
    "\n",
    "2.The values for both the 'rating_numerator' and 'rating_denominator' columns do not follow one standard scale.\n",
    "\n",
    "3.The values for the name column includes false names eg. english words such as 'a','the','an',etc. apart from proper nouns for dogs.\n",
    "\n",
    "4.Many column names do not accurately communicate their descriptions.\n",
    "\n",
    "5.Many tweets have been repeated as can be seen by the duplicates in the 'expanded_urls' column.\n",
    "\n",
    "6.There are a majority of null values in columns such as 'in_reply_to_status_id', 'in_reply_to_user_id',etc.\n",
    "\n",
    "***image_data***\n",
    "\n",
    "7.The values in the 'p1_dog','p2_dog','p3_dog' columns are both 'True' and 'False', indicating that some rows of the Table are not associated with dogs.\n",
    "\n",
    "8.The elements in the values of the 'p1','p2' and 'p3' columns are seperated by '_' instead of ' '.\n",
    "\n",
    "### Tidiness issues:\n",
    "\n",
    "1.The values for the 'doggo','floofer','pupper' and 'puppo' columns can be appended into a single column.\n",
    "\n",
    "2.The most probable dog breed for each row should be represented in one column. This column may be informed from the 'p1','p2','p3' columns.\n",
    "\n",
    "3.All tables need to be concatnated.\n",
    "\n",
    "\n",
    "The cleaning process which included removing duplicates, fixing errors, filtering outliers, handling missing data was undertaken.\n",
    "\n",
    "\n",
    "The Table generated from the twitter archive .csv file was named as ‘t_archive’, and a copy of this table (t_archive_copy) was used for assessing and cleaning. I first inspected this table as a whole and then each column on its own. I started from changing the data type of the timestamps for each tweet. Then I separated all the duplicated tweets which were the ‘responses to tweets’ and the ‘retweets’ being misrepresented as tweets. I standardized the ratings for each tweet so that they may be comparable with one another. The separate columns for each of the four nicknames used by @WeRateDogs were appended into a single column titled ‘nicknames. I then removed the columns with the redundant or missing information and renamed some column to better reflect the data stored in said columns.\n",
    "              \n",
    "              \n",
    "The tsv. file was converted into a table titled ‘image_data’. A copy of this table (image_data_copy) was then used for data assessment and cleaning. False predictions, where all three columns ‘p1_dog’,’p2_dog’,’p3_dog’ (predicting whether a row a tweet was about a dog or not) returned values of False, were removed from the table. A separate column (breed) for the most likely dog breed for each tweet was added. Data from three different columns ‘p1’,’p2’,’p3’ given predictions on the dog breed for each tweet was appended into column ‘breed’. \n",
    "    \n",
    "    \n",
    "The json data from the twitter API tweepy was converted into the table titled ‘j_df’. This data which was required from this table was extracted and a copy of the extracted data was stored in another table titled ‘j_copy’. The column with the tweet ids was renamed for consistency.\n",
    "    \n",
    "    \n",
    "All three tables were then merged into one dataframe called ‘merged_all’. The wrangling and cleaning process was saved into a .csv file 'twitter_archive_master.csv'.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
